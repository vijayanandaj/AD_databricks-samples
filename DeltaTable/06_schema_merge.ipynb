{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b99bc73b-df4b-4ace-a50c-762e58756427",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#07 Schema Merge feature\n",
    "from pyspark.sql import SparkSession\n",
    "from delta.tables import DeltaTable\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "path = \"dbfs:/FileStore/delta_merge_demo\"\n",
    "\n",
    "# CLEAN UP\n",
    "dbutils.fs.rm(path, recurse=True)\n",
    "\n",
    "# ── Step A: Create base table ──\n",
    "# IDs 1–4 with vals A–D\n",
    "spark.createDataFrame(\n",
    "    [(1, \"A\"), (2, \"B\"), (3, \"C\"), (4, \"D\")],\n",
    "    [\"id\", \"val\"]\n",
    ").write.format(\"delta\").mode(\"overwrite\").save(path)\n",
    "\n",
    "print(\"Initial (version 0):\")\n",
    "display(spark.read.format(\"delta\").load(path).orderBy(\"id\"))\n",
    "\n",
    "# ── Step B: Prepare updates ──\n",
    "# id=1 updated, id=2 marked for delete, id=5 new\n",
    "updates = spark.createDataFrame(\n",
    "    [(1, \"A'\"), (2, None), (5, \"E\")],\n",
    "    [\"id\", \"val\"]\n",
    ")\n",
    "\n",
    "# ── Step C: MERGE\n",
    "delta_tbl = DeltaTable.forPath(spark, path)\n",
    "(delta_tbl.alias(\"t\")\n",
    "  .merge(\n",
    "     source = updates.alias(\"s\"),\n",
    "     condition = \"t.id = s.id\"\n",
    "  )\n",
    "  .whenMatchedUpdate(condition=\"s.val IS NOT NULL\", set={\"val\": \"s.val\"})\n",
    "  .whenMatchedDelete(condition=\"s.val IS NULL\")\n",
    "  .whenNotMatchedInsert(values={\"id\": \"s.id\", \"val\": \"s.val\"})\n",
    "  .execute()\n",
    ")\n",
    "\n",
    "print(\"After MERGE (version 1):\")\n",
    "display(spark.read.format(\"delta\").load(path).orderBy(\"id\"))\n",
    "\n",
    "# ── Inspect history ──\n",
    "print(\"DESCRIBE HISTORY:\")\n",
    "spark.sql(f\"DESCRIBE HISTORY delta.`{path}`\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "06_schema_merge",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
