{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1ad5418d-e04c-4057-86e7-8e7edf38e098",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 01_Bronze.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.functions import current_timestamp, lit\n",
    "import os\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ─── 1) Derive a unique process_id ────────────────────────────────────────────\n",
    "#conf       = spark.conf.getAll()\n",
    "#process_id = f\"daily_ingest|{conf.get('spark.databricks.job.id','interactive')}_{conf.get('spark.databricks.job.#runId','interactive')}\"\n",
    "\n",
    "all_conf   = spark.conf.getAll   # note the ()\n",
    "job_id     = all_conf.get(\"spark.databricks.job.id\",   \"interactive\")\n",
    "run_id     = all_conf.get(\"spark.databricks.job.runId\", \"interactive\")\n",
    "process_id = f\"daily_ingest|{job_id}_{run_id}\"\n",
    "\n",
    "\n",
    "# ─── 2) Define the Bronze schema ─────────────────────────────────────────────\n",
    "bronze_schema = StructType([\n",
    "    StructField(\"user_id\",         StringType(), True),\n",
    "    StructField(\"app_name\",        StringType(), True),\n",
    "    StructField(\"event_type\",      StringType(), True),\n",
    "    StructField(\"event_timestamp\", StringType(), True),\n",
    "    StructField(\"device\", StructType([\n",
    "        StructField(\"os\",     StringType(), True),\n",
    "        StructField(\"region\", StringType(), True)\n",
    "    ]), True)\n",
    "])\n",
    "\n",
    "# ─── 3) Ensure the raw folder exists under DBFS /tmp ─────────────────────────\n",
    "raw_path = \"/tmp/raw/telemetry\"\n",
    "if not os.path.exists(f\"/dbfs{raw_path}\"):\n",
    "    dbutils.fs.mkdirs(f\"dbfs:{raw_path}\")\n",
    "    # Optionally drop in sample JSON:\n",
    "    # dbutils.fs.put(f\"dbfs:{raw_path}/sample1.json\", '{\"user_id\":\"u1\",\"app_name\":\"PS\",...}', True)\n",
    "\n",
    "# ─── 4) Read the raw JSON into our Bronze schema ─────────────────────────────\n",
    "raw_df = (spark.read\n",
    "    .schema(bronze_schema)\n",
    "    .option(\"multiline\", True)\n",
    "    .json(raw_path)\n",
    ")\n",
    "\n",
    "# ─── 5) Enrich with audit columns ─────────────────────────────────────────────\n",
    "bronze_df = (raw_df\n",
    "    .withColumn(\"ingest_ts\",  current_timestamp())\n",
    "    .withColumn(\"process_id\", lit(process_id))\n",
    ")\n",
    "\n",
    "# ─── 6) Write to Bronze Delta (overwrite for idempotence) ────────────────────\n",
    "bronze_path = \"dbfs:/tmp/bronze/cc_events\"\n",
    "bronze_df.write \\\n",
    "    .format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option(\"mergeSchema\",\"true\") \\\n",
    "    .save(bronze_path)\n",
    "\n",
    "# ─── 7) Register Bronze in Hive Metastore for SQL access ─────────────────────\n",
    "\n",
    "\n",
    "spark.sql(f\"\"\"USE CATALOG spark_catalog;\"\"\")   \n",
    "# -- the legacy HMS catalog\n",
    "spark.sql(f\"\"\"USE SCHEMA default;\"\"\")        \n",
    "#-- or whichever HM DB you prefer\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE TABLE IF NOT EXISTS bronze_cc_events\n",
    "  USING DELTA\n",
    "  LOCATION '{bronze_path}'\n",
    "\"\"\")\n",
    "\n",
    "# ─── 8) Sanity-check ─────────────────────────────────────────────────────────\n",
    "display(spark.read.format(\"delta\").load(bronze_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a5595ed4-4b2f-4fa8-b077-a9e07a73f55f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "01_Bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
