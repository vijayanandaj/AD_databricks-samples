{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b62e04f-9d35-4ea8-90fb-59adacf1e803",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#This does the following \n",
    "#--Below is a self-contained demo you can run in a Databricks notebook (attached to a Spark cluster).  It creates a tiny Delta table under /tmp/scratch_demo/mytable, shows you exactly how the schema lives in the JSON log, evolves when you ALTER it, and finally how a checkpoint Parquet bundles all of that metadata for Spark to read.\n",
    "\n",
    "\n",
    "\n",
    "dbutils.fs.rm(\"/tmp/scratch_demo\", recurse=True)\n",
    "dbutils.fs.mkdirs(\"/tmp/scratch_demo\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86cf34fc-190f-4310-be2c-1c35b3f9c38a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- v0: Create your initial Delta table (version 0)\n",
    "\n",
    "CREATE OR REPLACE TABLE delta.`/tmp/scratch_demo/mytable` (\n",
    "  id   INT,\n",
    "  val  STRING\n",
    ")\n",
    "USING DELTA;\n",
    "\n",
    "-- Insert a single row so we get an \"add\" in the log\n",
    "%sql\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (1, 'alpha');\n",
    "\n",
    "-- Inspect the raw JSON log for v0\n",
    "\n",
    "SELECT *\n",
    "FROM json.`/tmp/scratch_demo/mytable/_delta_log/00000000000000000000.json`\n",
    "-- You’ll see the first \"metaData\" with schemaString containing {\"fields\":[{\"name\":\"id\",…},{\"name\":\"val\",…}]}, and one or more \"add\" actions.\n",
    "\n",
    "-- v1: Evolve your schema via ALTER TABLE (version 1)\n",
    "\n",
    "ALTER TABLE delta.`/tmp/scratch_demo/mytable`\n",
    "  ADD COLUMNS (\n",
    "    new_col DOUBLE\n",
    "  );\n",
    "\n",
    "-- append a row that uses the new column]\n",
    "\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` \n",
    "VALUES (2, 'beta', 2.5);\n",
    "\n",
    "--Inspect the JSON log for v1\n",
    "\n",
    "SELECT *\n",
    "FROM json.`/tmp/scratch_demo/mytable/_delta_log/00000000000000000001.json`;\n",
    "-- Now you’ll see a second \"metaData\" entry whose schemaString includes the new_col field.\n",
    "\n",
    "-- v2–v10: Generate more commits so we trigger a checkpoint\n",
    "\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (3,'gamma',3.0);\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (4,'delta',4.0);\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (5,'epsilon',5.0);\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (6,'zeta',6.0);\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (7,'eta',7.0);\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (8,'theta',8.0);\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (9,'iota',9.0);\n",
    "INSERT INTO delta.`/tmp/scratch_demo/mytable` VALUES (10,'kappa',10.0);\n",
    "-- After the 10th commit, Delta writes a checkpoint Parquet called\n",
    "-- /tmp/scratch_demo/mytable/_delta_log/00000000000000000010.checkpoint.parquet\n",
    "\n",
    "--force a checkpoint\n",
    "\n",
    "ALTER TABLE delta.`/tmp/scratch_demo/mytable`\n",
    "  SET TBLPROPERTIES ('delta.checkpointInterval' = '1');\n",
    "\n",
    "-- 7) Examine the checkpoint Parquet\n",
    "\n",
    "-- List the log folder so you can see the checkpoint file\n",
    "\n",
    "%fs ls /tmp/scratch_demo/mytable/_delta_log\n",
    "\n",
    "-- in SQL\n",
    "\n",
    "\n",
    "-- Show only the metadata rows inside the checkpoint\n",
    "\n",
    "SELECT\n",
    "  version,\n",
    "  metaData.schemaString\n",
    "FROM parquet.`/tmp/scratch_demo/mytable/_delta_log/00000000000000000010.checkpoint.parquet`\n",
    "WHERE metaData IS NOT NULL;\n",
    "\n",
    "-- You’ll see two (or more) schemaString values: the one from v0, the one from v1 (with new_col), etc., and the last one is the live schema Spark uses.\n",
    "\n",
    "-- 8) Let Delta read via its abstraction\n",
    "\n",
    "\n",
    "DESCRIBE DETAIL delta.`/tmp/scratch_demo/mytable`;\n",
    "DESCRIBE HISTORY delta.`/tmp/scratch_demo/mytable`;\n",
    "\t--•\tDESCRIBE DETAIL shows the current schema (pulled from the last checkpoint’s metadata).\n",
    "\t--•\tDESCRIBE HISTORY shows version 0→10, with your WRITE and ALTER operations logged.\n",
    "\n",
    "  --Essence \n",
    "\t--1.\tSchema lives in the JSON log (metaData.schemaString in v0).\n",
    "\t--2.\tALTER TABLE emits a new metadata entry in v1.\n",
    "\t-- 3.\tCheckpoint at v10 bundles all metadata actions into a Parquet snapshot.\n",
    "\t--4.\tDelta engine (DESCRIBE DETAIL/HISTORY) reads the checkpoint directly—no JSON replay needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6c933439-09b7-4d01-b988-62d72bb8f2e0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- This uses the HMS/Unity Catalog lookup for `default.mytable`.\n",
    "-- Since we only ever wrote to the filesystem path, this should error:\n",
    "\n",
    "SELECT *\n",
    "FROM default.mytable;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c2d4506-6ca1-4721-8d44-444c2eab5529",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "-- 1) Switch to the Hive metastore catalog\n",
    "USE CATALOG hive_metastore;\n",
    "\n",
    "-- 2) (Re)create the default schema if needed\n",
    "CREATE SCHEMA IF NOT EXISTS default;\n",
    "\n",
    "-- 3) Register your Delta files as an external Hive table\n",
    "CREATE TABLE IF NOT EXISTS default.mytable\n",
    "USING DELTA\n",
    "LOCATION 'dbfs:/tmp/scratch_demo/mytable';\n",
    "\n",
    "-- 4) Now this will succeed:\n",
    "SELECT * FROM default.mytable;\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8003251843687346,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Basic_delta_plus_Checkpoint",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
