{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c35045c-cdb8-4617-b415-980c8b96e582",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .appName(\"BronzeSilverGold_Imperative_InMemory\")\n",
    "      .enableHiveSupport()\n",
    "      .getOrCreate()\n",
    ")\n",
    "\n",
    "# 1. In-memory raw data → Bronze\n",
    "raw = [\n",
    "    (1, \"click\",    \"2025-08-01T10:00:00\"),\n",
    "    (2, \"view\",     \"2025-08-01T10:01:00\"),\n",
    "    (1, \"purchase\", \"bad_ts\"),            # bad timestamp row\n",
    "    (3, \"click\",    \"2025-08-01T10:02:00\")\n",
    "]\n",
    "cols = [\"user_id\",\"event_type\",\"ts\"]\n",
    "df_raw = spark.createDataFrame(raw, cols)\n",
    "\n",
    "# Write and register Bronze\n",
    "bronze_path = \"/tmp/demo/bronze\"\n",
    "df_raw.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(bronze_path)\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo\")\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.bronze_events\")\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE TABLE demo.bronze_events\n",
    "  USING DELTA\n",
    "  LOCATION '{bronze_path}'\n",
    "\"\"\")\n",
    "\n",
    "# 2. Read Bronze → clean → Silver\n",
    "bronze_df = spark.read.format(\"delta\").table(\"demo.bronze_events\")\n",
    "silver_df = (\n",
    "    bronze_df\n",
    "      .filter(col(\"ts\").rlike(r\"^\\d{{4}}-\\d{{2}}-\\d{{2}}T\"))\n",
    "      .withColumn(\"ts\", col(\"ts\").cast(\"timestamp\"))\n",
    ")\n",
    "\n",
    "# Write and register Silver\n",
    "silver_path = \"/tmp/demo/silver\"\n",
    "silver_df.write.format(\"delta\") \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .save(silver_path)\n",
    "spark.sql(\"DROP TABLE IF EXISTS demo.silver_events\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d0cb1db-11cf-4c2e-a7ac-4bc71d9c20f8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, current_timestamp\n",
    "\n",
    "# Start SparkSession with Hive support\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "      .appName(\"DLT_InMemory_Demo\")\n",
    "      .enableHiveSupport()\n",
    "      .getOrCreate()\n",
    ")\n",
    "\n",
    "# Reuse same in-memory Bronze table (registered above) as streaming source:\n",
    "@dlt.table(\n",
    "    comment=\"Bronze: raw events\",\n",
    "    table_properties={\"delta.enableChangeDataFeed\":\"true\"}\n",
    ")\n",
    "def bronze_events():\n",
    "    return (\n",
    "      spark.readStream\n",
    "           .table(\"demo.bronze_events\")\n",
    "    )\n",
    "\n",
    "# Silver: clean & enforce quality\n",
    "@dlt.table(\n",
    "    comment=\"Silver: cleaned events\",\n",
    "    partition_cols=[\"event_date\"]\n",
    ")\n",
    "@dlt.expect_or_drop(\"valid_ts\", \"ts IS NOT NULL\")\n",
    "def silver_events():\n",
    "    return (\n",
    "      dlt.read_stream(\"bronze_events\")\n",
    "         .filter(\"event_type IS NOT NULL\")\n",
    "         .withColumn(\"ts\", col(\"ts\").cast(\"timestamp\"))\n",
    "         .withColumn(\"event_date\", col(\"ts\").cast(\"date\"))\n",
    "    )\n",
    "\n",
    "# Gold: aggregate counts\n",
    "@dlt.table(comment=\"Gold: per-user counts\")\n",
    "def gold_event_counts():\n",
    "    return (\n",
    "      dlt.read(\"silver_events\")\n",
    "         .groupBy(\"user_id\")\n",
    "         .count()\n",
    "         .withColumnRenamed(\"count\",\"event_count\")\n",
    "         .withColumn(\"as_of\", current_timestamp())\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DLT",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
