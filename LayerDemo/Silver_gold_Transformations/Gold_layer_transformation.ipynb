{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3e1d9a1-188a-425c-81f3-94c779e565d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# gold layer transformations\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# 0) Read the Silver table\n",
    "spark.sql(\"USE CATALOG spark_catalog\")\n",
    "spark.sql(\"USE default\")\n",
    "\n",
    "silver = spark.table(\"silver_covid_nyt\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) Build the fact: daily totals by region\n",
    "# ----------------------------------------------------------------------------\n",
    "gold_fact = (\n",
    "    silver\n",
    "      .groupBy(\"event_date\", \"region\")\n",
    "      .agg(\n",
    "        sum(\"cases\" ).alias(\"total_cases\"),\n",
    "        sum(\"deaths\").alias(\"total_deaths\"),\n",
    "        count(\"*\"   ).alias(\"event_count\")\n",
    "      )\n",
    "      .withColumn(\"year\",  year(\"event_date\"))\n",
    "      .withColumn(\"month\", month(\"event_date\"))\n",
    "      .withColumn(\"day\",   dayofmonth(\"event_date\"))\n",
    ")\n",
    "\n",
    "print(\"=== gold_fact (daily totals) ===\")\n",
    "display(gold_fact.limit(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) Build a small date dimension\n",
    "# ----------------------------------------------------------------------------\n",
    "dim_date = (\n",
    "    gold_fact\n",
    "      .select(\"event_date\")\n",
    "      .distinct()\n",
    "      .withColumn(\"year\",   year(\"event_date\"))\n",
    "      .withColumn(\"month\",  month(\"event_date\"))\n",
    "      .withColumn(\"day\",    dayofmonth(\"event_date\"))\n",
    "      .withColumn(\"weekday\", date_format(\"event_date\",\"E\"))\n",
    "      .withColumn(\"is_weekend\", expr(\"weekday IN ('Sat','Sun')\"))\n",
    ")\n",
    "\n",
    "print(\"=== dim_date (date dimension) ===\")\n",
    "display(dim_date.limit(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) Build the region dimension\n",
    "# ----------------------------------------------------------------------------\n",
    "# For demo, infer from Silver (in real life, use a master dim table)\n",
    "dim_region = (\n",
    "    silver\n",
    "      .select(\"region\")\n",
    "      .distinct()\n",
    "      .withColumnRenamed(\"region\",\"region_code\")\n",
    "      .withColumn(\"region_name\", initcap(col(\"region_code\")))\n",
    ")\n",
    "\n",
    "print(\"=== dim_region (region dimension) ===\")\n",
    "display(dim_region)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4) Join into a classic star: gold_covid_star\n",
    "# ----------------------------------------------------------------------------\n",
    "gold_star = (\n",
    "    gold_fact\n",
    "      .join(dim_date,   on=\"event_date\",    how=\"left\")\n",
    "      .join(dim_region, on=gold_fact.region == dim_region.region_code, how=\"left\")\n",
    "      .select(\n",
    "        col(\"event_date\"),\n",
    "        col(\"year\"      ).alias(\"fact_year\"),\n",
    "        col(\"month\"     ).alias(\"fact_month\"),\n",
    "        col(\"day\"       ).alias(\"fact_day\"),\n",
    "        col(\"region\"    ).alias(\"region_code\"),\n",
    "        col(\"region_name\"),\n",
    "        \"total_cases\",\"total_deaths\",\"event_count\",\n",
    "        \"weekday\",\"is_weekend\"\n",
    "      )\n",
    ")\n",
    "\n",
    "print(\"=== gold_star (fact + dims) ===\")\n",
    "display(gold_star.limit(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5) Final QC: no null keys\n",
    "# ----------------------------------------------------------------------------\n",
    "null_keys = gold_star.filter(col(\"event_date\").isNull() | col(\"region_code\").isNull())\n",
    "assert null_keys.count() == 0, \"Found null keys in Gold star schema!\"\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6) Register in Hive Metastore (spark_catalog) or Unity Catalog\n",
    "# ----------------------------------------------------------------------------\n",
    "# Example: Hive Metastore in database `exampledb`\n",
    "spark.sql(\"USE CATALOG spark_catalog; USE exampledb\")\n",
    "gold_fact.write.mode(\"overwrite\") .format(\"delta\") \\\n",
    "      .option(\"path\",\"dbfs:/tmp/gold/covid_daily_metrics_Transformation_ex\") \\\n",
    "      .saveAsTable(\"covid_daily_metrics_Transformation_ex\")\n",
    "\n",
    "dim_date.write.mode(\"overwrite\").format(\"delta\") \\\n",
    "      .option(\"path\",\"dbfs:/tmp/gold/dim_date_Transformation_ex\") \\\n",
    "      .saveAsTable(\"dim_date_Transformation_ex\")\n",
    "\n",
    "dim_region.write.mode(\"overwrite\").format(\"delta\") \\\n",
    "      .option(\"path\",\"dbfs:/tmp/gold/dim_region_Transformation_ex\") \\\n",
    "      .saveAsTable(\"dim_region_Transformation_ex\")\n",
    "\n",
    "gold_star.write.mode(\"overwrite\").format(\"delta\") \\\n",
    "      .option(\"path\",\"dbfs:/tmp/gold/covid_star_Transformation_ex\") \\\n",
    "      .saveAsTable(\"covid_covid_star_Transformation_ex\")\n",
    "\n",
    "print(\"✅ Gold layer tables written and registered.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "54682295-e45e-4865-b965-f2759dcfce73",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, month, dayofmonth, date_format, expr, sum as sum_, count\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# 0) point at the right catalog & schema\n",
    "spark.sql(\"USE CATALOG spark_catalog\")\n",
    "spark.sql(\"USE default\")\n",
    "\n",
    "# 1) read the Silver table\n",
    "silver = spark.table(\"silver_covid_nyt\")\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 1) Build the fact: daily totals by region, *renaming* the date parts\n",
    "# ----------------------------------------------------------------------------\n",
    "gold_fact = (\n",
    "    silver\n",
    "      .groupBy(\"event_date\", \"region\")\n",
    "      .agg(\n",
    "        sum_(\"cases\" ).alias(\"total_cases\"),\n",
    "        sum_(\"deaths\").alias(\"total_deaths\"),\n",
    "        count(\"*\"   ).alias(\"event_count\")\n",
    "      )\n",
    "      # rename the date‐part columns here\n",
    "      .withColumn(\"fact_year\",  year(\"event_date\"))\n",
    "      .withColumn(\"fact_month\", month(\"event_date\"))\n",
    "      .withColumn(\"fact_day\",   dayofmonth(\"event_date\"))\n",
    ")\n",
    "\n",
    "print(\"=== gold_fact (daily totals) ===\")\n",
    "display(gold_fact.limit(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 2) Build a small date dimension, using *the same* event_date but new names\n",
    "# ----------------------------------------------------------------------------\n",
    "dim_date = (\n",
    "    gold_fact\n",
    "      .select(\"event_date\")\n",
    "      .distinct()\n",
    "      .withColumn(\"date_year\",   year(\"event_date\"))\n",
    "      .withColumn(\"date_month\",  month(\"event_date\"))\n",
    "      .withColumn(\"date_day\",    dayofmonth(\"event_date\"))\n",
    "      .withColumn(\"weekday\",     date_format(\"event_date\",\"E\"))\n",
    "      .withColumn(\"is_weekend\",  expr(\"weekday IN ('Sat','Sun')\"))\n",
    ")\n",
    "\n",
    "print(\"=== dim_date (date dimension) ===\")\n",
    "display(dim_date.limit(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 3) Build the region dimension\n",
    "# ----------------------------------------------------------------------------\n",
    "dim_region = (\n",
    "    silver\n",
    "      .select(\"region\")\n",
    "      .distinct()\n",
    "      .withColumnRenamed(\"region\",\"region_code\")\n",
    "      .withColumn(\"region_name\", expr(\"initcap(region_code)\"))\n",
    ")\n",
    "\n",
    "print(\"=== dim_region (region dimension) ===\")\n",
    "display(dim_region.limit(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 4) Join into a classic star: gold_covid_star\n",
    "# ----------------------------------------------------------------------------\n",
    "gold_star = (\n",
    "    gold_fact\n",
    "      # join to date dim on the shared event_date\n",
    "      .join(dim_date,   on=\"event_date\", how=\"left\")\n",
    "      #join to region dim, fully qualifying ambiguous `region`\n",
    "      .join(dim_region, gold_fact[\"region\"] == dim_region[\"region_code\"], how=\"left\")\n",
    "      .select(\n",
    "        col(\"event_date\"),\n",
    "        col(\"fact_year\"),\n",
    "        col(\"fact_month\"),\n",
    "        col(\"fact_day\"),\n",
    "        col(\"region\"   ).alias(\"region_code\"),\n",
    "        col(\"region_name\"),\n",
    "        col(\"total_cases\"),\n",
    "        col(\"total_deaths\"),\n",
    "        col(\"event_count\"),\n",
    "        col(\"weekday\"),\n",
    "        col(\"is_weekend\")\n",
    "      )\n",
    ")\n",
    "\n",
    "print(\"=== gold_star (fact + dims) ===\")\n",
    "display(gold_star.limit(5))\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 5) Sanity‐check: no null keys\n",
    "# ----------------------------------------------------------------------------\n",
    "null_keys = gold_star.filter(\n",
    "    col(\"event_date\").isNull() |\n",
    "    col(\"region_code\").isNull()\n",
    ")\n",
    "assert null_keys.count() == 0, f\"Null keys! {null_keys.count()} rows\"\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "# 6) Write & register into Hive metastore\n",
    "# ----------------------------------------------------------------------------\n",
    "spark.sql(\"USE CATALOG spark_catalog\"); \n",
    "spark.sql(\"USE default\");\n",
    "\n",
    "gold_fact.write.mode(\"overwrite\").format(\"delta\").option(\"path\",\"dbfs:/tmp/gold/covid_daily_metrics_tr_gold\").saveAsTable(\"gold_covid_daily_metrics_tr_gold\")\n",
    "\n",
    "dim_date.write.mode(\"overwrite\").format(\"delta\").option(\"path\",\"dbfs:/tmp/gold/dim_date_tr_gold\").saveAsTable(\"gold_dim_date_tr_gold\")\n",
    "\n",
    "dim_region.write.mode(\"overwrite\").format(\"delta\").option(\"path\",\"dbfs:/tmp/gold/dim_region_tr_gold\").saveAsTable(\"gold_dim_region_tr_gold\")\n",
    "\n",
    "gold_star.write.mode(\"overwrite\").format(\"delta\").option(\"path\",\"dbfs:/tmp/gold/covid_star_tr_gold\").saveAsTable(\"gold_covid_star_tr_gold\")\n",
    "\n",
    "print(\"✅ Gold layer tables written and registered.\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Gold_layer_transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
