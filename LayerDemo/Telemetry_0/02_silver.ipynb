{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fed81f7b-409c-4950-8b99-30b2c7da72b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 02_Silver.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp, to_date\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from delta.tables import DeltaTable\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# ─── 1) Paths ─────────────────────────────────────────────────────────────────\n",
    "bronze_path = \"/tmp/bronze/cc_events\"\n",
    "silver_path = \"/tmp/silver/cc_events_enterprise\"\n",
    "ref_dir     = \"/tmp/reference\"\n",
    "ref_file    = f\"{ref_dir}/cc_features.csv\"\n",
    "\n",
    "# ─── 2) Bootstrap reference CSV if needed ─────────────────────────────────────\n",
    "try:\n",
    "    dbutils.fs.ls(f\"dbfs:{ref_dir}\")\n",
    "except Exception:\n",
    "    dbutils.fs.mkdirs(f\"dbfs:{ref_dir}\")\n",
    "    csv_content = \"\"\"app_name,event_type,feature_category\n",
    "Photoshop,launch,application\n",
    "Photoshop,feature_used,core_feature\n",
    "Illustrator,launch,application\n",
    "Illustrator,export,export_feature\n",
    "\"\"\"\n",
    "    dbutils.fs.put(f\"dbfs:{ref_file}\", csv_content, overwrite=True)\n",
    "\n",
    "# ─── 3) Read Bronze Delta ────────────────────────────────────────────────────\n",
    "bronze_df = spark.read.format(\"delta\").load(bronze_path)\n",
    "\n",
    "# ─── 4) Cleanse, flatten, cast, dedupe ───────────────────────────────────────\n",
    "silver_ready = (\n",
    "    bronze_df\n",
    "      .filter(col(\"user_id\").isNotNull() & col(\"event_type\").isNotNull())\n",
    "      .withColumn(\"event_ts\",  to_timestamp(\"event_timestamp\",\"yyyy-MM-dd'T'HH:mm:ss'Z'\"))\n",
    "      .withColumn(\"event_date\", to_date(\"event_ts\"))\n",
    "      .withColumn(\"os\",     col(\"device.os\"))\n",
    "      .withColumn(\"region\", col(\"device.region\"))\n",
    "      .select(\"user_id\",\"app_name\",\"event_type\",\n",
    "              \"event_ts\",\"event_date\",\"os\",\"region\",\n",
    "              \"ingest_ts\",\"process_id\")\n",
    "      .dropDuplicates([\"user_id\",\"app_name\",\"event_type\",\"event_ts\"])\n",
    ")\n",
    "\n",
    "# ─── 5) Read the reference CSV ────────────────────────────────────────────────\n",
    "feature_schema = StructType([\n",
    "    StructField(\"app_name\",        StringType(), True),\n",
    "    StructField(\"event_type\",      StringType(), True),\n",
    "    StructField(\"feature_category\",StringType(), True)\n",
    "])\n",
    "feature_ref = (spark.read\n",
    "    .option(\"header\", True)\n",
    "    .schema(feature_schema)\n",
    "    .csv(ref_file)\n",
    ")\n",
    "\n",
    "# ─── 6) Join to enrich / conform ─────────────────────────────────────────────\n",
    "silver_enriched = silver_ready.join(\n",
    "    feature_ref,\n",
    "    on=[\"app_name\",\"event_type\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# ─── 7) Idempotent upsert into Silver Delta ─────────────────────────────────\n",
    "if DeltaTable.isDeltaTable(spark, silver_path):\n",
    "    DeltaTable.forPath(spark, silver_path) \\\n",
    "      .alias(\"s\") \\\n",
    "      .merge(\n",
    "        silver_enriched.alias(\"b\"),\n",
    "        \"s.user_id = b.user_id AND s.app_name = b.app_name AND s.event_ts = b.event_ts\"\n",
    "      ) \\\n",
    "      .whenMatchedUpdateAll() \\\n",
    "      .whenNotMatchedInsertAll() \\\n",
    "      .execute()\n",
    "else:\n",
    "    silver_enriched.write.format(\"delta\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(silver_path)\n",
    "    spark.sql(f\"\"\"\n",
    "      CREATE TABLE IF NOT EXISTS silver_cc_events_enterprise\n",
    "      USING DELTA LOCATION '{silver_path}'\n",
    "    \"\"\")\n",
    "\n",
    "# ─── 8) Verify Silver output ────────────────────────────────────────────────\n",
    "display(spark.read.format(\"delta\").load(silver_path))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
